{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복 실험을 위한 Sacred\n",
    "- [Sacred Github](https://github.com/IDSIA/sacred)\n",
    "- Sacred란?\n",
    "    - Sacred is a tool to help you configure, organize, log and reproduce experiments developed at IDSIA\n",
    "    - 머신러닝 모델링을 진행할 때 설정을 저장해주고 관리하는 것을 도와주는 도구\n",
    "- 왜 필요한가요?\n",
    "    - Kaggle에서 자주 발생하는 예시\n",
    "        - 사용한 Feature는?\n",
    "        - 사용한 파라미터는?\n",
    "        - 그 결과는?\n",
    "    - 다양한 실험을 빠르게 진행하며, 손으로 기록하지 않고 자동으로 기록될 수 있도록 도와줄 도구가 필요\n",
    "- Scratch로 구현하면?\n",
    "    - Logger를 정의해서 필요할 때마다 Logger에 Feature, 파라미터 등을 저장\n",
    "    - 값을 보기 위해 Logger를 Parsing\n",
    "- Sacred는 위 방법을 데코레이터로 쉽게 사용할 수 있도록 도와줌\n",
    "    - MLOps와 관련되는 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sacred의 Main mechanisms\n",
    "    - ConfigScopes : 함수의 local 변수를 편리하게 다룰 수 있음 @ex.config 데코레이터로 사용\n",
    "    - Config Injection : 모든 함수에 있는 설정을 접근할 수 있음\n",
    "    - Command-line interface : 커맨드 라인으로 파라미터를 바꿔서 실행할 수 있음\n",
    "    - Observers : 실험의 모든 정보를 Observers에게 제공해 저장. MongoDB / S3 등 => 이번 강의에선 그냥 로컬에 저장\n",
    "    - Automatic seeding : 실험의 무작위를 컨트롤할 때 도와줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacred\n",
      "  Downloading sacred-0.8.1.tar.gz (90 kB)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.0 in c:\\users\\younjiei\\anaconda3\\lib\\site-packages (from sacred) (1.12.1)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\younjiei\\anaconda3\\lib\\site-packages (from sacred) (0.4.3)\n",
      "Requirement already satisfied: packaging>=18.0 in c:\\users\\younjiei\\anaconda3\\lib\\site-packages (from sacred) (20.3)\n",
      "Collecting docopt<1.0,>=0.3\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting GitPython\n",
      "  Downloading GitPython-3.1.11-py3-none-any.whl (159 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "Collecting jsonpickle<2.0,>=1.2\n",
      "  Downloading jsonpickle-1.4.2-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\younjiei\\anaconda3\\lib\\site-packages (from jsonpickle<2.0,>=1.2->sacred) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\younjiei\\anaconda3\\lib\\site-packages (from importlib-metadata->jsonpickle<2.0,>=1.2->sacred) (2.2.0)\n",
      "Collecting munch<3.0,>=2.0.2\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: six in c:\\users\\younjiei\\anaconda3\\lib\\site-packages (from munch<3.0,>=2.0.2->sacred) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\younjiei\\anaconda3\\lib\\site-packages (from packaging>=18.0->sacred) (2.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\younjiei\\anaconda3\\lib\\site-packages (from munch<3.0,>=2.0.2->sacred) (1.14.0)\n",
      "Collecting py-cpuinfo>=4.0\n",
      "  Downloading py-cpuinfo-7.0.0.tar.gz (95 kB)\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Downloading smmap-3.0.4-py2.py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: sacred, docopt, py-cpuinfo\n",
      "  Building wheel for sacred (setup.py): started\n",
      "  Building wheel for sacred (setup.py): finished with status 'done'\n",
      "  Created wheel for sacred: filename=sacred-0.8.1-py2.py3-none-any.whl size=105023 sha256=f4d31d3ca3311e36994bc02c3120dd9296597c0d840990b3b5a14f26e123a963\n",
      "  Stored in directory: c:\\users\\younjiei\\appdata\\local\\pip\\cache\\wheels\\3c\\ac\\e1\\2f746c47edc95a1cf43119706c787efd9c307a8b3d4a649308\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13709 sha256=5c4196263282b42df6128e533c078398e7a7013f251aee1cd6f004e3d6571974\n",
      "  Stored in directory: c:\\users\\younjiei\\appdata\\local\\pip\\cache\\wheels\\72\\b0\\3f\\1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "  Building wheel for py-cpuinfo (setup.py): started\n",
      "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-py3-none-any.whl size=20074 sha256=ebe981d6f75a47bd9af1801c485bae9355680b1325481f166312565171892ef2\n",
      "  Stored in directory: c:\\users\\younjiei\\appdata\\local\\pip\\cache\\wheels\\d7\\59\\0d\\58c5e576d9192261fa3da00466eebe6f7a1ac1873a7ab1f2ce\n",
      "Successfully built sacred docopt py-cpuinfo\n",
      "Installing collected packages: smmap, gitdb, py-cpuinfo, munch, jsonpickle, GitPython, docopt, sacred\n",
      "Successfully installed GitPython-3.1.11 docopt-0.6.2 gitdb-4.0.5 jsonpickle-1.4.2 munch-2.5.0 py-cpuinfo-7.0.0 sacred-0.8.1 smmap-3.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\younjiei\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sacred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공식 홈페이지 Sacred 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "from numpy.random import permutation\n",
    "from sklearn import svm, datasets\n",
    "from sacred import Experiment\n",
    "from sacred.observers import FileStorageObserver\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "PROJECT_ID='nycproject-297915' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook에선 interactive=True 지정해줘야 하고, 스크립트 형식이라면 이 옵션이 필요 없음\n",
    "ex = Experiment('iris_rbf_svm', interactive=True)\n",
    "\n",
    "# Decorator로 config 저장\n",
    "@ex.config\n",
    "def cfg():\n",
    "    C = 1.0\n",
    "    gamma = 0.7\n",
    "\n",
    "# ex.main을 지정 => 이 때 cfg에 있는 인자들이 자동으로 injection됨\n",
    "# 또한 Notebook에선 ex.main을 쓰고 스크립트 파일에선 ex.automain을 사용\n",
    "@ex.main\n",
    "def run(C, gamma):\n",
    "    iris = datasets.load_iris()\n",
    "    per = permutation(iris.target.size)\n",
    "    iris.data = iris.data[per]\n",
    "    iris.target = iris.target[per]\n",
    "    clf = svm.SVC(C, 'rbf', gamma=gamma)\n",
    "    clf.fit(iris.data[:90],\n",
    "          iris.target[:90])\n",
    "    return clf.score(iris.data[90:],\n",
    "                   iris.target[90:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - iris_rbf_svm - No observers have been added to this run\n",
      "INFO - iris_rbf_svm - Running command 'run'\n",
      "INFO - iris_rbf_svm - Started\n",
      "INFO - iris_rbf_svm - Result: 0.95\n",
      "INFO - iris_rbf_svm - Completed after 0:00:00\n"
     ]
    }
   ],
   "source": [
    "run_result = ex.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'gamma': 0.7, 'seed': 666370240}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_result.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_result.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'iris_rbf_svm',\n",
       " 'base_dir': 'C:\\\\Users\\\\Younjiei\\\\Desktop\\\\패스트캠퍼스\\\\머신러닝&데이터분석\\\\4. [실전프로젝트]\\\\03. 뉴욕(NYC) 택시수요 예측 Project\\\\PART 3) NYC 택시 수요 예측',\n",
       " 'sources': [],\n",
       " 'dependencies': ['ipython==7.13.0',\n",
       "  'ipywidgets==7.5.1',\n",
       "  'matplotlib==3.1.3',\n",
       "  'numpy==1.18.1',\n",
       "  'pandas==1.1.4',\n",
       "  'sacred==0.8.1',\n",
       "  'scikit-learn==0.22.1',\n",
       "  'seaborn==0.11.0'],\n",
       " 'repositories': [],\n",
       " 'mainfile': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_result.experiment_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존 프로젝트에 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Experiment('nyc-demand-prediction', interactive=True)\n",
    "\n",
    "# experiment_dir가 없으면 폴더 생성하고 FileStorageObserver로 저장\n",
    "experiment_dir = os.path.join('./', 'experiments')\n",
    "if not os.path.isdir(experiment_dir): \n",
    "    os.makedirs(experiment_dir)\n",
    "ex.observers.append(FileStorageObserver.create(experiment_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - pandas_gbq.gbq - Total time taken 8.2 s.\n",
      "Finished at 2020-12-13 15:55:55.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_query = \"\"\"\n",
    "WITH base_data AS \n",
    "(\n",
    "  SELECT nyc_taxi.*, gis.* EXCEPT (zip_code_geom)\n",
    "  FROM (\n",
    "    SELECT *\n",
    "    FROM `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2015`\n",
    "    WHERE \n",
    "        EXTRACT(MONTH from pickup_datetime) = 1\n",
    "        and pickup_latitude  <= 90 and pickup_latitude >= -90\n",
    "    ) AS nyc_taxi\n",
    "  JOIN (\n",
    "    SELECT zip_code, state_code, state_name, city, county, zip_code_geom\n",
    "    FROM `bigquery-public-data.geo_us_boundaries.zip_codes`\n",
    "    WHERE state_code='NY'\n",
    "    ) AS gis \n",
    "  ON ST_CONTAINS(zip_code_geom, st_geogpoint(pickup_longitude, pickup_latitude))\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    zip_code,\n",
    "    DATETIME_TRUNC(pickup_datetime, hour) as pickup_hour,\n",
    "    EXTRACT(MONTH FROM pickup_datetime) AS month,\n",
    "    EXTRACT(DAY FROM pickup_datetime) AS day,\n",
    "    CAST(format_datetime('%u', pickup_datetime) AS INT64) -1 AS weekday,\n",
    "    EXTRACT(HOUR FROM pickup_datetime) AS hour,\n",
    "    CASE WHEN CAST(FORMAT_DATETIME('%u', pickup_datetime) AS INT64) IN (6, 7) THEN 1 ELSE 0 END AS is_weekend,\n",
    "    COUNT(*) AS cnt\n",
    "FROM base_data \n",
    "GROUP BY zip_code, pickup_hour, month, day, weekday, hour, is_weekend\n",
    "ORDER BY pickup_hour\n",
    "\"\"\"\n",
    "\n",
    "base_df = pd.read_gbq(query=base_query, dialect='standard', project_id='nycproject-297915')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feautre Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(base_df[['zip_code']])\n",
    "ohe_output = enc.transform(base_df[['zip_code']]).toarray()\n",
    "ohe_df = pd.concat([base_df, pd.DataFrame(ohe_output, columns='zip_code_'+enc.categories_[0])], axis=1)\n",
    "ohe_df['log_cnt'] = np.log10(ohe_df['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test(df, date):\n",
    "    \"\"\"\n",
    "    Dataframe에서 train_df, test_df로 나눠주는 함수\n",
    "    \n",
    "    df : 시계열 데이터 프레임\n",
    "    date : 기준점 날짜\n",
    "    \"\"\"\n",
    "    train_df = df[df['pickup_hour'] < date]\n",
    "    test_df = df[df['pickup_hour'] >= date]\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_train_and_test(ohe_df, '2015-01-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>cnt</th>\n",
       "      <th>zip_code_10001</th>\n",
       "      <th>zip_code_10002</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_code_12729</th>\n",
       "      <th>zip_code_12771</th>\n",
       "      <th>zip_code_13029</th>\n",
       "      <th>zip_code_13118</th>\n",
       "      <th>zip_code_13656</th>\n",
       "      <th>zip_code_13691</th>\n",
       "      <th>zip_code_14072</th>\n",
       "      <th>zip_code_14527</th>\n",
       "      <th>zip_code_14801</th>\n",
       "      <th>log_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65113</th>\n",
       "      <td>10007</td>\n",
       "      <td>2015-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.181844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65114</th>\n",
       "      <td>11432</td>\n",
       "      <td>2015-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65115</th>\n",
       "      <td>11369</td>\n",
       "      <td>2015-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65116</th>\n",
       "      <td>11421</td>\n",
       "      <td>2015-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65117</th>\n",
       "      <td>10475</td>\n",
       "      <td>2015-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      zip_code         pickup_hour  month  day  weekday  hour  is_weekend  \\\n",
       "65113    10007 2015-01-23 23:00:00      1   23        4    23           0   \n",
       "65114    11432 2015-01-23 23:00:00      1   23        4    23           0   \n",
       "65115    11369 2015-01-23 23:00:00      1   23        4    23           0   \n",
       "65116    11421 2015-01-23 23:00:00      1   23        4    23           0   \n",
       "65117    10475 2015-01-23 23:00:00      1   23        4    23           0   \n",
       "\n",
       "       cnt  zip_code_10001  zip_code_10002  ...  zip_code_12729  \\\n",
       "65113  152             0.0             0.0  ...             0.0   \n",
       "65114    1             0.0             0.0  ...             0.0   \n",
       "65115    5             0.0             0.0  ...             0.0   \n",
       "65116    1             0.0             0.0  ...             0.0   \n",
       "65117    1             0.0             0.0  ...             0.0   \n",
       "\n",
       "       zip_code_12771  zip_code_13029  zip_code_13118  zip_code_13656  \\\n",
       "65113             0.0             0.0             0.0             0.0   \n",
       "65114             0.0             0.0             0.0             0.0   \n",
       "65115             0.0             0.0             0.0             0.0   \n",
       "65116             0.0             0.0             0.0             0.0   \n",
       "65117             0.0             0.0             0.0             0.0   \n",
       "\n",
       "       zip_code_13691  zip_code_14072  zip_code_14527  zip_code_14801  \\\n",
       "65113             0.0             0.0             0.0             0.0   \n",
       "65114             0.0             0.0             0.0             0.0   \n",
       "65115             0.0             0.0             0.0             0.0   \n",
       "65116             0.0             0.0             0.0             0.0   \n",
       "65117             0.0             0.0             0.0             0.0   \n",
       "\n",
       "        log_cnt  \n",
       "65113  2.181844  \n",
       "65114  0.000000  \n",
       "65115  0.698970  \n",
       "65116  0.000000  \n",
       "65117  0.000000  \n",
       "\n",
       "[5 rows x 383 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용하지 않을 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['zip_code']\n",
    "del train_df['pickup_hour']\n",
    "del test_df['zip_code']\n",
    "del test_df['pickup_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>cnt</th>\n",
       "      <th>zip_code_10001</th>\n",
       "      <th>zip_code_10002</th>\n",
       "      <th>zip_code_10003</th>\n",
       "      <th>zip_code_10004</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_code_12729</th>\n",
       "      <th>zip_code_12771</th>\n",
       "      <th>zip_code_13029</th>\n",
       "      <th>zip_code_13118</th>\n",
       "      <th>zip_code_13656</th>\n",
       "      <th>zip_code_13691</th>\n",
       "      <th>zip_code_14072</th>\n",
       "      <th>zip_code_14527</th>\n",
       "      <th>zip_code_14801</th>\n",
       "      <th>log_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.568202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.806180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  day  weekday  hour  is_weekend  cnt  zip_code_10001  zip_code_10002  \\\n",
       "0      1    1        3     0           0   37             0.0             0.0   \n",
       "1      1    1        3     0           0   64             0.0             0.0   \n",
       "\n",
       "   zip_code_10003  zip_code_10004  ...  zip_code_12729  zip_code_12771  \\\n",
       "0             0.0             0.0  ...             0.0             0.0   \n",
       "1             0.0             0.0  ...             0.0             0.0   \n",
       "\n",
       "   zip_code_13029  zip_code_13118  zip_code_13656  zip_code_13691  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   zip_code_14072  zip_code_14527  zip_code_14801   log_cnt  \n",
       "0             0.0             0.0             0.0  1.568202  \n",
       "1             0.0             0.0             0.0  1.806180  \n",
       "\n",
       "[2 rows x 381 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = train_df.pop('cnt')\n",
    "y_train_log = train_df.pop('log_cnt')\n",
    "y_test_raw = test_df.pop('cnt')\n",
    "y_test_log = test_df.pop('log_cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test_raw.values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.copy()\n",
    "x_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    score = pd.DataFrame([mape, mae, mse], index=['mape', 'mae', 'mse'], columns=['score']).T\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 설정\n",
    "- 위에서 ex = Experiment('nyc-demand-prediction', interactive=True)했는데, ex.config로 설정을 저장\n",
    "- ex.capture는 해당 설정을 사용해 함수를 리턴\n",
    "- ex.main은 실험이 실행될 때 진행할 내용을 담음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def config():\n",
    "    fit_intercept=True\n",
    "    normalize=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.capture\n",
    "def get_model(fit_intercept, normalize):\n",
    "    return LinearRegression(fit_intercept, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _log과 _run은 별도로 정의하지 않아도 함수의 인자로 사용 가능\n",
    "@ex.main\n",
    "def run(_log, _run):\n",
    "    lr_reg = get_model()\n",
    "    lr_reg.fit(x_train, y_train_raw)\n",
    "    pred = lr_reg.predict(x_test)\n",
    "    # log File에 로그 저장\n",
    "    _log.info(\"Predict End\")\n",
    "    score = evaluation(y_test_raw, pred)\n",
    "    _run.log_scalar('model_name', lr_reg.__class__.__name__)\n",
    "    \n",
    "    # Metrics쪽에 저장하고 싶으면 아래처럼 사용\n",
    "    _run.log_scalar('metrics', score)\n",
    "    \n",
    "    # Result쪽에 저장하고 싶으면 아래처럼 사용\n",
    "    return score.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - nyc-demand-prediction - Running command 'run'\n",
      "INFO - nyc-demand-prediction - Started run with ID \"2\"\n",
      "INFO - run - Predict End\n",
      "INFO - nyc-demand-prediction - Result: {'mape': {'score': 206173998524.95016}, 'mae': {'score': 2107556502.4600215}, 'mse': {'score': 4.22974661985608e+21}}\n",
      "INFO - nyc-demand-prediction - Completed after 0:00:01\n"
     ]
    }
   ],
   "source": [
    "experiment_result = ex.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True, 'normalize': False, 'seed': 923771811}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_result.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 확인하기 위한 Parser\n",
    "- Experiment에서 log찍는 방식에 따라 사용할 함수가 다름\n",
    "    - 1) \\_run.log\\_scalar에 metrics을 저장하는 경우 \n",
    "    - 2) @ex.main의 함수에 결과를 return하는 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    " import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) _run.log_scalar에 metrics을 저장하는 경우\n",
    "def parsing_output(ex_id):\n",
    "    with open(f'./experiments/{ex_id}/metrics.json') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    with open(f'./experiments/{ex_id}/config.json') as config_file:\n",
    "        config_data = json.load(config_file)\n",
    "    \n",
    "    output_df = pd.DataFrame(json_data['model_name']['values'], columns=['model_name'], index=['score'])\n",
    "    output_df['experiment_num'] = ex_id\n",
    "    output_df['config'] = str(config_data)\n",
    "    metric_df = pd.DataFrame(json_data['metrics']['values'][0]['values'])\n",
    "    \n",
    "    output_df = pd.concat([output_df, metric_df], axis=1)\n",
    "    output_df = output_df.round(2)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) @ex.main의 함수에 결과를 return하는 경우\n",
    "def parsing_output(ex_id):\n",
    "    with open(f'./experiments/{ex_id}/run.json') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    output = pd.DataFrame(json_data['result'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>2.107557e+09</td>\n",
       "      <td>2.061740e+11</td>\n",
       "      <td>4.229747e+21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mae          mape           mse\n",
       "score  2.107557e+09  2.061740e+11  4.229747e+21"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing_output(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더 자세한 내용\n",
    "- [Sacred Github](https://github.com/IDSIA/sacred)\n",
    "- [머신러닝 실험을 도와줄 Python Sacred 소개](https://zzsza.github.io/mlops/2019/07/21/python-sacred/)\n",
    "- [Sacred와 Omniboard를 활용한 실험 및 로그 모니터링](https://zzsza.github.io/mlops/2019/07/22/sacred-with-omniboard/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
